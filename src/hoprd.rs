use std::collections::hash_map::DefaultHasher;
use std::sync::Arc;
use std::time::Duration;
use std::hash::{Hash, Hasher};

use crate::hoprd_deployment_spec::HoprdDeploymentSpec;
use crate::{constants, hoprd_service_monitor, hoprd_ingress, hoprd_deployment, hoprd_secret, hoprd_service, utils, context_data::ContextData, cluster::ClusterHoprd};
use crate::model::{ClusterHoprdStatusEnum, HoprdStatusEnum, EnablingFlag, HoprdSecret, Error};
use crate::hoprd_persistence;
use chrono::Utc;
use k8s_openapi::apimachinery::pkg::apis::meta::v1::OwnerReference;
use kube::Resource;
use kube::runtime::events::{Recorder, EventType, Event};
use schemars::JsonSchema;
use serde::{Serialize, Deserialize};
use serde_json::{json};
use kube::{
    api::{Api, Patch, PatchParams, ResourceExt},
    client::Client,
    runtime::{
        controller::{Action}
    },
    CustomResource, Result
};

/// Struct corresponding to the Specification (`spec`) part of the `Hoprd` resource, directly
/// reflects context of the `hoprds.hoprnet.org.yaml` file to be found in this repository.
/// The `Hoprd` struct will be generated by the `CustomResource` derive macro.
#[derive(CustomResource, Serialize, Deserialize, Debug, PartialEq, Clone, JsonSchema, Hash)]
#[kube(
    group = "hoprnet.org",
    version = "v1alpha",
    kind = "Hoprd",
    plural = "hoprds",
    derive = "PartialEq",
    namespaced
)]
#[kube(status = "HoprdStatus", shortname = "hoprd")]
#[serde(rename_all = "camelCase")]
pub struct HoprdSpec {
    pub config: Option<HoprdConfig>,
    pub enabled: Option<bool>,
    pub network: String,
    pub ingress: Option<EnablingFlag>,
    pub monitoring: Option<EnablingFlag>,
    pub deployment: Option<HoprdDeploymentSpec>,
    pub secret: Option<HoprdSecret>,
    pub version: String,

}

#[derive(Serialize, Deserialize, Debug, PartialEq, Default, Clone, JsonSchema, Hash)]
pub struct HoprdConfig {
    pub announce: Option<bool>,
    pub provider: Option<String>,
    pub default_strategy: Option<String>,
    pub max_auto_channels: Option<i32>,
    #[serde(rename(deserialize = "autoRedeemTickets"))]
    pub auto_redeem_tickets: Option<bool>,
    pub check_unrealized_balance: Option<bool>,
    pub allow_private_node_connections: Option<bool>,
    pub test_announce_local_address: Option<bool>,
    pub heartbeat_interval: Option<i32>,
    pub heartbeat_threshold: Option<i32>,
    pub heartbeat_variance: Option<i32>,
    pub on_chain_confirmations: Option<i32>,
    pub network_quality_threshold: Option<u32>
}

/// The status object of `Hoprd`
#[derive(Serialize, Deserialize, Debug, PartialEq, Clone, JsonSchema)]
pub struct HoprdStatus {
    pub update_timestamp: i64,
    pub status: HoprdStatusEnum,
    pub checksum: String,
}

impl Hoprd {

    // Creates all the related resources
    pub async fn create(&self, context: Arc<ContextData>) -> Result<Action> {
        let client: Client = context.client.clone();
        let hoprd_namespace: String = self.namespace().unwrap();
        let hoprd_name: String= self.name_any();
        self.create_event(context.clone(), HoprdStatusEnum::Initializing).await.unwrap();
        self.update_status(context.clone(), HoprdStatusEnum::Initializing).await.unwrap();
        println!("[INFO] Starting to create Hoprd node {hoprd_name} in namespace {hoprd_namespace}");
        let owner_reference: Option<Vec<OwnerReference>> = Some(vec![self.controller_owner_ref(&()).unwrap()]);
        self.add_finalizer(client.clone(), &hoprd_name, &hoprd_namespace).await.unwrap();
        // Invoke creation of a Kubernetes resources
        let mut secret_manager = hoprd_secret::SecretManager::new(context.clone(), self.clone());
        match secret_manager.create_secret().await {
            Ok(secret) => {
                hoprd_persistence::create_pvc(context.clone(), &self).await?;
                hoprd_deployment::create_deployment(client.clone(), &self,  secret).await?;
                hoprd_service::create_service(client.clone(), &hoprd_name, &hoprd_namespace, owner_reference.to_owned()).await?;
                if self.spec.ingress.as_ref().unwrap_or(&EnablingFlag {enabled: constants::ENABLED}).enabled {
                    hoprd_ingress::create_ingress(client.clone(), &hoprd_name, &hoprd_namespace,&context.config.ingress, owner_reference.to_owned()).await?;
                }
                if self.spec.monitoring.as_ref().unwrap_or(&EnablingFlag {enabled: constants::ENABLED}).enabled {
                    hoprd_service_monitor::create_service_monitor(client.clone(), &hoprd_name, &hoprd_namespace, &secret_manager.hoprd_secret.unwrap(), owner_reference.to_owned()).await?;
                }
                println!("[INFO] Hoprd node {hoprd_name} in namespace {hoprd_namespace} has been successfully created");
                Ok(Action::requeue(Duration::from_secs(constants::RECONCILE_FREQUENCY)))
            },
            Err(error) => {
                println!("[ERROR]: {:?}", error);
                Ok(Action::requeue(Duration::from_secs(constants::RECONCILE_FREQUENCY)))
            }
        }

    }

    // Creates all the related resources
    pub async fn modify(&self, context: Arc<ContextData>) -> Result<Action> {
        let client: Client = context.client.clone();
        let hoprd_namespace: String = self.namespace().unwrap();
        let hoprd_name: String= self.name_any();
        println!("[INFO] Hoprd node {hoprd_name} in namespace {hoprd_namespace} has been successfully modified");
        self.create_event(context.clone(), HoprdStatusEnum::Reloading).await.unwrap();
        self.update_status(context.clone(), HoprdStatusEnum::Reloading).await.unwrap();
        let annotations = utils::get_resource_kinds(client.clone(), utils::ResourceType::Hoprd, utils::ResourceKind::Annotations, &hoprd_name, &hoprd_namespace).await;
        if annotations.contains_key(constants::ANNOTATION_LAST_CONFIGURATION) {
            let previous_config_text: String = annotations.get_key_value(constants::ANNOTATION_LAST_CONFIGURATION).unwrap().1.parse().unwrap();
            match serde_json::from_str::<Hoprd>(&previous_config_text) {
                Ok(modified_hoprd) => {
                    self.check_inmutable_fields(&modified_hoprd.spec).unwrap();
                    let secret_manager = hoprd_secret::SecretManager::new(context.clone(), self.clone());
                    let secret = secret_manager.get_hoprd_secret().await.unwrap();
                    if secret.is_some() {
                        let hoprd_secret = self.spec.secret.as_ref().unwrap_or(&HoprdSecret { secret_name: secret.unwrap().name_any(), ..HoprdSecret::default() }).to_owned();
                        hoprd_deployment::modify_deployment(client.clone(), &hoprd_name.to_owned(), &hoprd_namespace.to_owned(), &modified_hoprd.spec.to_owned(), hoprd_secret).await?;
                    } else {
                        println!("[WARN] Hoprd node {hoprd_name} does not have a linked secret and is inconsistent");
                    }
                },
                Err(_err) => {
                    println!("[ERROR] Could not parse the last applied configuration of Hoprd node {hoprd_name}.");
                }
            }
        }
        Ok(Action::requeue(Duration::from_secs(constants::RECONCILE_FREQUENCY)))
    }

    // Deletes all the related resources
    pub async fn delete(&self, context: Arc<ContextData>) -> Result<Action> {
        let hoprd_name = self.name_any();
        let hoprd_namespace = self.namespace().unwrap();
        let client: Client = context.client.clone();
        self.create_event(context.clone(), HoprdStatusEnum::Deleting).await.unwrap();
        println!("[INFO] Starting to delete Hoprd node {hoprd_name} from namespace {hoprd_namespace}");
        // Deletes any subresources related to this `Hoprd` resources. If and only if all subresources
        // are deleted, the finalizer is removed and Kubernetes is free to remove the `Hoprd` resource.
        if self.spec.monitoring.as_ref().unwrap_or(&EnablingFlag {enabled: constants::ENABLED}).enabled {
            hoprd_service_monitor::delete_service_monitor(client.clone(), &hoprd_name, &hoprd_namespace).await?;
        }
        if self.spec.ingress.as_ref().unwrap_or(&EnablingFlag {enabled: constants::ENABLED}).enabled {
            hoprd_ingress::delete_ingress(client.clone(), &hoprd_name, &hoprd_namespace).await?;
        }
        hoprd_service::delete_service(client.clone(), &hoprd_name, &hoprd_namespace).await?;
        hoprd_deployment::delete_depoyment(client.clone(), &hoprd_name, &hoprd_namespace).await.unwrap();
        let secret_manager = hoprd_secret::SecretManager::new(context.clone(), self.clone());
        secret_manager.unlock_secret().await.unwrap();
        // Once all the resources are successfully removed, remove the finalizer to make it possible
        // for Kubernetes to delete the `Hoprd` resource.
        self.create_event(context.clone(), HoprdStatusEnum::Deleted).await.unwrap();
        self.delete_finalizer(client.clone(), &hoprd_name, &hoprd_namespace).await.unwrap();
        println!("[INFO] Hoprd node {hoprd_name} in namespace {hoprd_namespace} has been successfully deleted");
        self.notify_cluster(context.clone()).await.unwrap();
        Ok(Action::await_change()) // Makes no sense to delete after a successful delete, as the resource is gone
    }

    /// Adds a finalizer record into an `Hoprd` kind of resource. If the finalizer already exists,
    /// this action has no effect.
    ///
    /// # Arguments:
    /// - `client` - Kubernetes client to modify the `Hoprd` resource with.
    /// - `hoprd_name` - Name of the `Hoprd` resource to modify. Existence is not verified
    /// - `hoprd_namespace` - Namespace where the `Hoprd` resource with given `name` resides.
    ///
    async fn add_finalizer(&self, client: Client, hoprd_name: &str, hoprd_namespace: &str) -> Result<Hoprd, Error> {
        let api: Api<Hoprd> = Api::namespaced(client.clone(), &hoprd_namespace.to_owned());
        let pp = PatchParams::default();
        let patch = json!({
           "metadata": {
                "finalizers": [constants::OPERATOR_FINALIZER]
            }
        });
        match api.patch(&hoprd_name, &pp, &Patch::Merge(patch)).await {
            Ok(hopr) => Ok(hopr),
            Err(error) => {
                println!("[ERROR]: {:?}", error);
                return Err(Error::HoprdStatusError(format!("Could not add finalizer on {hoprd_name}.").to_owned()));
            }
        }
    }

    /// Removes all finalizers from an `Hoprd` resource. If there are no finalizers already, this
    /// action has no effect.
    ///
    /// # Arguments:
    /// - `client` - Kubernetes client to modify the `Hoprd` resource with.
    /// - `hoprd_name` - Name of the `Hoprd` resource to modify. Existence is not verified
    /// - `hoprd_namespace` - Namespace where the `Hoprd` resource with given `name` resides.
    ///
    async fn delete_finalizer(&self, client: Client, hoprd_name: &str, hoprd_namespace: &str) -> Result<(), Error> {
        let api: Api<Hoprd> = Api::namespaced(client.clone(), &hoprd_namespace.to_owned());
        let pp = PatchParams::default();
        let patch = json!({
           "metadata": {
                "finalizers": null
            }
        });
        if let Some(_) = api.get_opt(&hoprd_name).await? {
            match api.patch(&hoprd_name, &pp, &Patch::Merge(patch)).await {
                Ok(_hopr) => Ok(()),
                Err(error) => {
                    println!("[ERROR]: {:?}", error);
                    return Err(Error::HoprdStatusError(format!("Could not delete finalizer on hoprd node {hoprd_name}.").to_owned()));
                }
            }
        } else {
            println!("[DEBUG] Hoprd node {hoprd_name} has already been deleted");
            Ok(())
        }
    }

    fn check_inmutable_fields(&self, spec: &HoprdSpec) -> Result<(),Error> {
        if ! self.spec.network.eq(&spec.network) {
            return Err(Error::HoprdConfigError(format!("Hoprd configuration is invalid, network field cannot be changed on {}.", self.name_any())));
        }
        if ! self.spec.secret.eq(&spec.secret) {
            return Err(Error::HoprdConfigError(format!("Hoprd configuration is invalid, secret field cannot be changed on {}.", self.name_any())));
        }
        Ok(())
    }

    /// Creates an event for ClusterHoprd given the new HoprdStatusEnum
    pub async fn create_event(&self, context: Arc<ContextData>, status: HoprdStatusEnum) -> Result<(), Error> {
        let client: Client = context.client.clone();
            
        let ev: Event = match status {
            HoprdStatusEnum::Initializing => Event {
                        type_: EventType::Normal,
                        reason: "Initializing".to_string(),
                        note: Some("Initializing Hoprd node".to_owned()),
                        action: "Starting the process of creating a new node".to_string(),
                        secondary: None,
                    },
            HoprdStatusEnum::Creating => Event {
                        type_: EventType::Normal,
                        reason: "Creating".to_string(),
                        note: Some("Creating Hoprd node repository and secrets".to_owned()),
                        action: "Node secrets are being created".to_string(),
                        secondary: None,
                    },
            HoprdStatusEnum::RegisteringInNetwork => Event {
                        type_: EventType::Normal,
                        reason: "RegisteringInNetwork".to_string(),
                        note: Some("Hoprd node created but not registered yet".to_owned()),
                        action: "Node is registering into the Network registry".to_string(),
                        secondary: None,
                    },
            HoprdStatusEnum::Funding => Event {
                        type_: EventType::Normal,
                        reason: "Funding".to_string(),
                        note: Some("Hoprd node created and registered but not funded yet".to_owned()),
                        action: "Node is being funded with mHopr and xDAI".to_string(),
                        secondary: None,
                    },
            HoprdStatusEnum::Stopped => Event {
                        type_: EventType::Normal,
                        reason: "Stopped".to_string(),
                        note: Some("Hoprd node is stopped".to_owned()),
                        action: "Node has stopped".to_string(),
                        secondary: None,
                    },
            HoprdStatusEnum::Running => Event {
                        type_: EventType::Normal,
                        reason: "Running".to_string(),
                        note: Some("Hoprd node is running".to_owned()),
                        action: "Node has started".to_string(),
                        secondary: None,
                    },
            HoprdStatusEnum::Reloading => Event {
                        type_: EventType::Normal,
                        reason: "Reloading".to_string(),
                        note: Some("Hoprd node configuration change detected".to_owned()),
                        action: "Node reconfigured".to_string(),
                        secondary: None,
                    },
            HoprdStatusEnum::Deleting => Event {
                        type_: EventType::Normal,
                        reason: "Deleting".to_string(),
                        note: Some("Hoprd node is being deleted".to_owned()),
                        action: "Node deletion started".to_string(),
                        secondary: None,
                    },
            HoprdStatusEnum::Deleted => Event {
                        type_: EventType::Normal,
                        reason: "Deleted".to_string(),
                        note: Some("Hoprd node is deleted".to_owned()),
                        action: "Node deletion finished".to_string(),
                        secondary: None,
                    },
            HoprdStatusEnum::OutOfSync => Event {
                        type_: EventType::Warning,
                        reason: "Out of sync".to_string(),
                        note: Some("Hoprd node is not sync".to_owned()),
                        action: "Node sync failed".to_string(),
                        secondary: None,
                    }

        };
        let recorder: Recorder = context.state.read().await.generate_hoprd_event(client.clone(), self);
        Ok(recorder.publish(ev).await?)

    }

    pub async fn update_status(&self, context: Arc<ContextData>, status: HoprdStatusEnum) -> Result<(), Error> {
        let client: Client = context.client.clone();
        let hoprd_name = self.metadata.name.as_ref().unwrap().to_owned();
        let hoprd_namespace = self.metadata.namespace.as_ref().unwrap().to_owned();

        let api: Api<Hoprd> = Api::namespaced(client.clone(), &hoprd_namespace.to_owned());
        if status.eq(&HoprdStatusEnum::Deleting) || status.eq(&HoprdStatusEnum::Deleted) {
            api.get(&hoprd_name).await?;
            Ok(())
        } else {
            let mut hasher: DefaultHasher = DefaultHasher::new();
            self.spec.clone().hash(&mut hasher);
            let hash: u64 = hasher.finish();
            let status = HoprdStatus {
                    update_timestamp: Utc::now().timestamp(),
                    status: status,
                    checksum: format!("checksum-{}",hash.to_string())
            };
            let pp = PatchParams::default();
            let patch = json!({
                    "status": status
            });
            //println!("[DEBUG] Updating hoprd {hoprd_name} to {:?} with spec {:?} and hash {hash}", status, self.spec);
            match api.patch(&hoprd_name, &pp, &Patch::Merge(patch)).await {
                Ok(_) => Ok(()),
                Err(error) => {
                    println!("[ERROR]: {:?}", error);
                    return Err(Error::HoprdStatusError(format!("Could not update status on node {hoprd_name}.")));
                }
            }
    }

    
}

    pub async fn notify_cluster(&self, context: Arc<ContextData>) -> Result<(), Error> {
        let hoprd_namespace = self.metadata.namespace.as_ref().unwrap().to_owned();
        let api: Api<ClusterHoprd> = Api::namespaced(context.client.clone(), &hoprd_namespace.to_owned());
        if let Some(owner_reference) = self.owner_references().to_owned().first() {
            if let Some(cluster) = api.get_opt(&owner_reference.name).await? {
                if cluster.to_owned().status.unwrap().status != ClusterHoprdStatusEnum::Deleting {
                    cluster.create_event(context.clone(), ClusterHoprdStatusEnum::OutOfSync, Some(self.name_any().to_owned())).await.unwrap();
                    cluster.update_status(context.clone(), ClusterHoprdStatusEnum::OutOfSync).await.unwrap();
                    println!("[INFO] Notifying ClusterHoprd {} that Hoprd node {} is being deleted", &owner_reference.name, self.name_any().to_owned())
                }
            } else {
                println!("[WARN] ClusterHoprd {} not found", &owner_reference.name);
            }
        };

        Ok(())
    }

}


